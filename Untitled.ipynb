{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a57577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "\n",
    "root_dir = Path('C:/Users/USER/Desktop/project/test')\n",
    "model_dir = root_dir / 'model'\n",
    "data_dir = root_dir / 'data'\n",
    "\n",
    "debug_dir = root_dir / 'debug'\n",
    "\n",
    "if not debug_dir.exists():\n",
    "    os.mkdir(debug_dir)\n",
    "\n",
    "bbox_path = 'C:/Users/USER/Desktop/project/test/data/oidv6-train-annotations-bbox.csv'\n",
    "\n",
    "face_id = '/m/0dzct'\n",
    "img_size = 640\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ec0d9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "14610229 Images find!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Loading Data...')\n",
    "df = pd.read_csv(bbox_path)\n",
    "print(f'{len(df)} Images find!\\nDone!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b727ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ImageID',\n",
       " 'Source',\n",
       " 'LabelName',\n",
       " 'Confidence',\n",
       " 'XMin',\n",
       " 'XMax',\n",
       " 'YMin',\n",
       " 'YMax',\n",
       " 'IsOccluded',\n",
       " 'IsTruncated',\n",
       " 'IsGroupOf',\n",
       " 'IsDepiction',\n",
       " 'IsInside',\n",
       " 'XClick1X',\n",
       " 'XClick2X',\n",
       " 'XClick3X',\n",
       " 'XClick4X',\n",
       " 'XClick1Y',\n",
       " 'XClick2Y',\n",
       " 'XClick3Y',\n",
       " 'XClick4Y']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d0b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[['ImageID', 'XMin', 'XMax', 'YMin', 'YMax', 'LabelName']]\n",
    "train_df = train_df[train_df['LabelName'] == face_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e05e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DataSet(Dataset):\n",
    "    def __init__(self, train_df, ths=0.046, DEBUG_MODE=False, is_train=False) -> None:\n",
    "        i = 0\n",
    "\n",
    "        self._train_set = []\n",
    "        self._ths = ths\n",
    "        self._DEBUG = DEBUG_MODE\n",
    "\n",
    "        for img, face, debug_img in Image_loader(train_df, self._ths):\n",
    "            if len(face) == 0:\n",
    "                continue\n",
    "            \n",
    "            if DEBUG_MODE:\n",
    "                debug_img.save(str(debug_dir / f\"test img {i}.jpg\"))\n",
    "            \n",
    "            train_data, train_label = Data_Pretreatment(img, face)\n",
    "            \n",
    "            print(len(train_data), train_label)\n",
    "            for idx in range(len(train_data)):\n",
    "                #self._train_set.append([train_data[idx], list(map(lambda x: int(x * img_size), [box for box in train_label[idx]]))])\n",
    "                self._train_set.append([train_data[idx], train_label[idx]])\n",
    "\n",
    "            i += 1\n",
    "            if i == 10:\n",
    "                break\n",
    "        \n",
    "        self._data_len = len(self._train_set)\n",
    "        self._indices = np.arange(self._data_len, dtype=np.uint)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        데이터 셋을 리턴\n",
    "        train_set: [train_data, train_label]\n",
    "        train_data: (image_size, image_size, 3)\n",
    "        train_label: (xmax, xmin, ymax, ymin, anchor_size)\n",
    "        '''\n",
    "        return self._train_set[idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "802f5ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_loader(df, ths):\n",
    "    import copy\n",
    "    iamge_dir = Path('C:/Users/USER/Desktop/project/test/data/[target_dir/train]')\n",
    "    \n",
    "    last_id = ''\n",
    "    faces = []\n",
    "    for idx, image in enumerate(df.values):\n",
    "        Id, xmin, xmax, ymin, ymax, _ = image\n",
    "        \n",
    "        if last_id == '':\n",
    "            img = Image.open(str(iamge_dir / (Id + '.jpg')))\n",
    "            w, h = img.size\n",
    "            debug_img = copy.deepcopy(img)\n",
    "            last_id = Id\n",
    "        \n",
    "        if last_id != Id or idx == len(df.values) - 1:\n",
    "            yield img.resize((img_size, img_size), Image.LANCZOS), faces, debug_img\n",
    "            faces = []\n",
    "            img = Image.open(str(iamge_dir / (Id + '.jpg')))\n",
    "            w, h = img.size\n",
    "            debug_img = copy.deepcopy(img)\n",
    "\n",
    "        last_id = Id        \n",
    "        if xmax - xmin < ths or ymax - ymin < ths:\n",
    "            continue\n",
    "        \n",
    "        debug_img = draw_face_line(debug_img, [w, h, xmax, xmin, ymax, ymin])\n",
    "        faces.append([xmax, xmin, ymax, ymin])\n",
    "        \n",
    "\n",
    "def draw_face_line(img, cord):\n",
    "    from PIL import ImageDraw\n",
    "    w, h, xmax, xmin, ymax, ymin = cord\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.rectangle(((int(w * xmin), int(h * ymin)), (int(w * xmax), int(h * ymax))), outline='green')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f49b1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Pretreatment(img, face):\n",
    "    new_img, new_label = argument(img, face)\n",
    "    new_label = rate2cord(new_label)\n",
    "    return new_img, new_label\n",
    "    \n",
    "def argument(img, faces):\n",
    "    from torchvision import transforms\n",
    "    new_image = [np.array(img)]\n",
    "    new_labels = [faces]\n",
    "\n",
    "    # crop_size_list = [0.3, 0.45, 0.6, 0.8, 1.0]\n",
    "    # ths = torch.randint(0, 5)\n",
    "    # if ths != 4:\n",
    "    #     crop_ratio = crop_size_list(ths)\n",
    "    #     crop_w, crop_h = img_size * crop_ratio, img_size * crop_ratio\n",
    "    #     image = np.array(transforms.RandomCrop((crop_h, crop_w))(img))\n",
    "    #     new_image.append(image)\n",
    "    #     for i in range(face_count):\n",
    "    #         face = np.array(faces[i])\n",
    "    #         new_face = face * crop_ratio\n",
    "    #         boxes.append(new_face)\n",
    "\n",
    "    image = transforms.RandomHorizontalFlip(0.5)(img)\n",
    "    if image != img:\n",
    "        new_image.append(np.array(image))\n",
    "        new_faces = []\n",
    "        for face in faces:\n",
    "            face = np.array(face)\n",
    "            new_face = [1 - face[1], 1 - face[0], face[2], face[3]]\n",
    "            new_faces.append(new_face)\n",
    "        new_labels.append(new_faces)\n",
    "    return new_image, new_labels\n",
    "\n",
    "def rate2cord(labels):\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        labels =[]\n",
    "        for l in label:\n",
    "            labels.append(list(map(lambda x: int(x * img_size), l)))\n",
    "        new_labels.append(labels)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e0f95cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRandom crop test\\nfrom torchvision import transforms\\nimg = Image.open(\\'C:/Users/USER/Desktop/project/test/data/[target_dir/train]/000004f4400f6ec5.jpg\\')\\nw, h = img.size\\nimg = transforms.RandomCrop((round(h * 0.8), round(w * 0.8)))(img)\\nimg.save(str(debug_dir / f\"test.jpg\"))\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Random crop test\n",
    "from torchvision import transforms\n",
    "img = Image.open('C:/Users/USER/Desktop/project/test/data/[target_dir/train]/000004f4400f6ec5.jpg')\n",
    "w, h = img.size\n",
    "img = transforms.RandomCrop((round(h * 0.8), round(w * 0.8)))(img)\n",
    "img.save(str(debug_dir / f\"test.jpg\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aff8881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[318, 275, 362, 198], [437, 364, 296, 139]]]\n",
      "1 [[[318, 275, 362, 198], [437, 364, 296, 139]]]\n",
      "[[[414, 230, 586, 238]], [[410, 226, 586, 238]]]\n",
      "2 [[[414, 230, 586, 238]], [[410, 226, 586, 238]]]\n",
      "[[[297, 208, 270, 146], [472, 380, 262, 142]], [[432, 342, 270, 146], [259, 167, 262, 142]]]\n",
      "2 [[[297, 208, 270, 146], [472, 380, 262, 142]], [[432, 342, 270, 146], [259, 167, 262, 142]]]\n",
      "[[[424, 244, 350, 148]]]\n",
      "1 [[[424, 244, 350, 148]]]\n",
      "[[[145, 114, 262, 186], [241, 206, 267, 208], [330, 292, 240, 152]], [[526, 494, 262, 186], [433, 398, 267, 208], [347, 309, 240, 152]]]\n",
      "2 [[[145, 114, 262, 186], [241, 206, 267, 208], [330, 292, 240, 152]], [[526, 494, 262, 186], [433, 398, 267, 208], [347, 309, 240, 152]]]\n",
      "[[[274, 188, 363, 170], [537, 459, 459, 314]]]\n",
      "1 [[[274, 188, 363, 170], [537, 459, 459, 314]]]\n",
      "[[[166, 116, 312, 219], [256, 201, 261, 154], [479, 400, 240, 91]]]\n",
      "1 [[[166, 116, 312, 219], [256, 201, 261, 154], [479, 400, 240, 91]]]\n",
      "[[[162, 115, 339, 202], [266, 229, 287, 147], [326, 255, 311, 166], [458, 362, 306, 100]], [[524, 477, 339, 202], [410, 374, 287, 147], [384, 313, 311, 166], [278, 182, 306, 100]]]\n",
      "2 [[[162, 115, 339, 202], [266, 229, 287, 147], [326, 255, 311, 166], [458, 362, 306, 100]], [[524, 477, 339, 202], [410, 374, 287, 147], [384, 313, 311, 166], [278, 182, 306, 100]]]\n",
      "[[[555, 296, 566, 102]]]\n",
      "1 [[[555, 296, 566, 102]]]\n",
      "[[[281, 250, 535, 481], [336, 305, 493, 435], [522, 491, 564, 463], [557, 526, 364, 323]]]\n",
      "1 [[[281, 250, 535, 481], [336, 305, 493, 435], [522, 491, 564, 463], [557, 526, 364, 323]]]\n"
     ]
    }
   ],
   "source": [
    "train_data = DataSet(train_df, DEBUG_MODE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "27e79f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[34, 39, 39],\n",
       "         [35, 38, 39],\n",
       "         [36, 36, 39],\n",
       "         ...,\n",
       "         [ 7,  5,  6],\n",
       "         [ 6,  4,  5],\n",
       "         [ 7,  5,  6]],\n",
       " \n",
       "        [[33, 38, 41],\n",
       "         [36, 38, 40],\n",
       "         [35, 39, 42],\n",
       "         ...,\n",
       "         [ 6,  4,  5],\n",
       "         [ 6,  6,  6],\n",
       "         [ 6,  6,  6]],\n",
       " \n",
       "        [[33, 37, 40],\n",
       "         [35, 37, 41],\n",
       "         [33, 38, 41],\n",
       "         ...,\n",
       "         [ 5,  5,  5],\n",
       "         [ 6,  6,  6],\n",
       "         [ 6,  6,  6]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[36, 29, 23],\n",
       "         [40, 33, 29],\n",
       "         [38, 33, 30],\n",
       "         ...,\n",
       "         [10,  8,  9],\n",
       "         [11,  9,  9],\n",
       "         [12, 11,  9]],\n",
       " \n",
       "        [[31, 26, 20],\n",
       "         [36, 29, 23],\n",
       "         [35, 30, 26],\n",
       "         ...,\n",
       "         [10,  8,  9],\n",
       "         [11,  9,  9],\n",
       "         [14, 13, 11]],\n",
       " \n",
       "        [[29, 23, 17],\n",
       "         [32, 25, 19],\n",
       "         [32, 27, 24],\n",
       "         ...,\n",
       "         [ 9,  7,  8],\n",
       "         [11,  9,  9],\n",
       "         [16, 15, 13]]], dtype=uint8),\n",
       " [[318, 275, 362, 198], [437, 364, 296, 139]]]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c3c06949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder:\n",
    "    def __init__(self) -> None:\n",
    "        self.base_scale = 2 ** (4/3)\n",
    "        anchor_scale_step = 2 ** (1/3)\n",
    "        self.base_anchor = [self.base_scale * pow(2, i) for i in range(2, 8)]\n",
    "        self.num_fms = 6\n",
    "\n",
    "        self.aspect_ratios = [1/2., 1/1., 2/1.]\n",
    "        self.anchor_scale = [self.base_scale * (anchor_scale_step ** i) for i in range(3)]\n",
    "        self.anchor_list = self._get_anchor_wh()\n",
    "\n",
    "    def _get_anchor_wh(self):\n",
    "        anchors = []\n",
    "\n",
    "        for anchor in self.base_anchor:\n",
    "            for ar in self.aspect_ratios:\n",
    "                h = anchor / ar\n",
    "                w = ar * h\n",
    "                for scale in self.anchor_scale:\n",
    "                    anchors.append([w * scale, h * scale])\n",
    "        \n",
    "        return torch.Tensor(anchors).view(self.num_fms, -1, 2)\n",
    "\n",
    "\n",
    "    def _get_anchor_boxes(self, input_size):\n",
    "        boxes = []\n",
    "        fm_sizes = [(input_size / i).ceil() for i in self.base_anchor]\n",
    "\n",
    "        for i in range(self.num_fms):\n",
    "            fm_size = fm_sizes[i]\n",
    "            grid_size = input_size / fm_size\n",
    "            fm_w, fm_h = int(fm_size[0]), int(fm_size[1])\n",
    "            xy = self._meshgrid(fm_w, fm_h) + 0.5\n",
    "            xy = (xy * grid_size).view(fm_h, fm_w, 1, 2).expand(fm_h, fm_w, 9, 2)\n",
    "            wh = self.anchor_list[i].view(1, 1, 9, 2).expand(fm_h, fm_w, 9, 2)\n",
    "            box = torch.cat([xy, wh], 3)\n",
    "            boxes.append(box.view(-1, 4))\n",
    "        return torch.cat(boxes, 0)\n",
    "            \n",
    "    \n",
    "    def _get_iou(self, boxes):\n",
    "        \"\"\"\n",
    "        box별 각 anchor들의 iou를 구함\n",
    "        \"\"\"\n",
    "        bbox = []\n",
    "        for box in boxes:\n",
    "            box_wh = np.array([box[2] * 2, box[3] * 2])\n",
    "            ious = []\n",
    "            for fms in range(self.num_fms):\n",
    "                fms_iou = []\n",
    "                for anchor in self.anchor_list[fms]:\n",
    "                    intersect_wh = np.maximum(np.minimum(box_wh, anchor), 0.0)\n",
    "                    intersect_area = intersect_wh[0] * intersect_wh[1]\n",
    "                    box_area = box_wh[0] * box_wh[1]\n",
    "                    anchor_area = anchor[0] * anchor[1]\n",
    "                    iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "                    fms_iou.append(iou)\n",
    "                ious.append(fms_iou)\n",
    "            bbox.append(ious)\n",
    "\n",
    "        return torch.Tensor(bbox)\n",
    "    \n",
    "    def _meshgrid(self, x, y, row_major=True):\n",
    "        a = torch.arange(0, x)\n",
    "        b = torch.arange(0, y)\n",
    "        xx = a.repeat(y).view(-1 ,1)\n",
    "        yy = b.view(-1, 1).repeat(1, x).view(-1, 1)\n",
    "        return torch.cat([xx, yy], 1) if row_major else torch.cat([yy, xx])\n",
    "\n",
    "    def encode(self, boxes, labels, input_size):\n",
    "        input_size = torch.Tensor([input_size, input_size]) if isinstance(input_size, int) else torch.Tensor(input_size)\n",
    "        anchor_boxes = self._get_anchor_boxes(input_size)\n",
    "        boxes = self._change_box_order(boxes, 'xxyy2xywh')\n",
    "\n",
    "        ious = self._get_iou(boxes)\n",
    "        best_ious, best_ids = ious.max(1)\n",
    "        print(best_ids, boxes)\n",
    "        boxes = boxes[best_ids]\n",
    "    \n",
    "        loc_xy = (boxes[:,:2] - anchor_boxes[:,:2]) / anchor_boxes[:,2:]\n",
    "        loc_wh = torch.log(boxes[:,2:]/anchor_boxes[:,2:])\n",
    "        loc_targets = torch.cat([loc_xy, loc_wh], 1)\n",
    "\n",
    "        # class 할당\n",
    "        cls_targets = 1 + labels[best_ids[idx]]\n",
    "        cls_targets[best_ious<0.35] = 0 # iou < 0.35 anchor는 negative\n",
    "        return loc_targets, cls_targets\n",
    "\n",
    "    def decode(self, loc_preds, cls_preds, input_size):\n",
    "        cls_thresh = 0.5\n",
    "        nms_thresh = 0.5\n",
    "\n",
    "        input_size = torch.Tensor([input_size,input_size]) if isinstance(input_size, int) else torch.Tensor(input_size)\n",
    "        anchor_boxes = self._get_anchor_boxes(input_size) # 앵커 박스 생성\n",
    "\n",
    "        loc_xy = loc_preds[:,:2] # 결과값 offset 추출\n",
    "        loc_wh = loc_preds[:,2:]\n",
    "\n",
    "        xy = loc_xy * anchor_boxes[:,2:] + anchor_boxes[:,:2] # offset + anchor\n",
    "        wh = loc_wh.exp() * anchor_boxes[:,2:]\n",
    "        boxes = torch.cat([xy-wh/2, xy+wh/2], 1)\n",
    "\n",
    "        score, labels = cls_preds.sigmoid().max(1)\n",
    "        ids = score > cls_thresh\n",
    "        ids = ids.nonzero().squeeze()\n",
    "        keep = self._box_nms(boxes[ids], score[ids], threshold=nms_thresh) # nms\n",
    "        return boxes[ids][keep], labels[ids][keep]\n",
    "    \n",
    "    def _change_box_order(self, boxes, order):\n",
    "        assert order in ['xxyy2xywh','xywh2xxyy']\n",
    "\n",
    "        if order == 'xxyy2xywh':\n",
    "            x = torch.div((boxes[:,0] + boxes[:,1]), 2, rounding_mode='trunc')\n",
    "            y = torch.div((boxes[:,2] + boxes[:,3]), 2, rounding_mode='trunc')\n",
    "            w = boxes[:,0] - boxes[:,1]\n",
    "            h = boxes[:,2] - boxes[:,3]\n",
    "            return torch.cat([x.view(-1, 1), y.view(-1, 1), w.view(-1, 1), h.view(-1, 1)], 1)\n",
    "        else:\n",
    "            x1 = boxes[:,0] + torch.div(boxes[:,2], 2, rounding_mode='trunc')\n",
    "            x2 = boxes[:,0] - torch.div(boxes[:,2], 2, rounding_mode='trunc')\n",
    "            y1 = boxes[:,1] + torch.div(boxes[:,3], 2, rounding_mode='trunc')\n",
    "            y2 = boxes[:,1] - torch.div(boxes[:,3], 2, rounding_mode='trunc')\n",
    "            return torch.cat([x1.view(-1, 1), x2.view(-1, 1), y1.view(-1, 1), y2.view(-1, 1)], 1)\n",
    "\n",
    "    def _box_nms(self, bboxes, scores, threshold=0.5, mode='union'):\n",
    "        x1 = bboxes[:,0]\n",
    "        y1 = bboxes[:,1]\n",
    "        x2 = bboxes[:,2]\n",
    "        y2 = bboxes[:,3]\n",
    "\n",
    "        areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        _, order = scores.sort(0, descending=True) # confidence 순 정렬\n",
    "        keep = []\n",
    "        while order.numel() > 0:\n",
    "            if order.numel() == 1:\n",
    "                keep.append(order.data)\n",
    "                break\n",
    "            i = order[0] # confidence 가장 높은 anchor 추출\n",
    "            keep.append(i) # 최종 detection에 저장\n",
    "\n",
    "            xx1 = x1[order[1:]].clamp(min=x1[i])\n",
    "            yy1 = y1[order[1:]].clamp(min=y1[i])\n",
    "            xx2 = x2[order[1:]].clamp(max=x2[i])\n",
    "            yy2 = y2[order[1:]].clamp(max=y2[i])\n",
    "\n",
    "            w = (xx2-xx1+1).clamp(min=0)\n",
    "            h = (yy2-yy1+1).clamp(min=0)\n",
    "            inter = w*h\n",
    "\n",
    "            if mode == 'union':\n",
    "                ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "            elif mode == 'min':\n",
    "                ovr = inter / areas[order[1:]].clamp(max=areas[i])\n",
    "            else:\n",
    "                raise TypeError('Unknown nms mode: %s.' % mode)\n",
    "\n",
    "            ids = (ovr<=threshold).nonzero().squeeze()\n",
    "            if ids.numel() == 0:\n",
    "                break\n",
    "            order = order[ids+1]\n",
    "        return torch.LongTensor(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "681373af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, df, batch_size) -> None:\n",
    "        self._df = np.array(df, dtype='object')\n",
    "        self._batch_size = batch_size\n",
    "        \n",
    "        self.encoder = encoder()\n",
    "        self._imgs = [img for img in self._df[:, 0]]\n",
    "        self._boxes = torch.stack([torch.Tensor(box) for box in self._df[:, 1]])\n",
    "\n",
    "        self._loc_targets = []\n",
    "        self._cls_targets = []\n",
    "\n",
    "        loc_target, cls_target = self.encoder.encode(self._boxes, [1 for _ in range(self.data_size())], input_size=(img_size, img_size))\n",
    "        self._loc_targets.append(loc_target)\n",
    "        self._cls_targets.append(cls_target)\n",
    "        \n",
    "\n",
    "    def next(self, idx):\n",
    "        start_idx = idx * self._batch_size\n",
    "        end_idx = min((idx + 1) * self._batch_size, self.len())\n",
    "        \n",
    "        return self._imgs[start_idx:end_idx], torch.stack(self._loc_targets[start_idx:end_idx]), torch.stack(self._cls_targets[start_idx:end_idx])\n",
    "\n",
    "    def data_size(self):\n",
    "        return len(self._df)\n",
    "\n",
    "    def iter(self):\n",
    "        from math import ceil\n",
    "        return ceil(self.len() / self._batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d577a73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 43., 164.],\n",
       "        [ 42., 164.],\n",
       "        [ 73., 157.],\n",
       "        [184., 348.],\n",
       "        [ 89., 124.],\n",
       "        [ 92., 120.],\n",
       "        [180., 202.],\n",
       "        [ 31.,  76.],\n",
       "        [ 35.,  59.],\n",
       "        [ 38.,  88.],\n",
       "        [ 86., 193.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[296.], [343.], [400.], [322.], [252.], [426.], [334.], [129.], [223.], [311.], [231.]])\n",
    "b = torch.Tensor([[280.], [280.], [217.], [412.], [208.], [202.], [249.], [224.], [237.], [196.], [266.]])\n",
    "c = torch.Tensor([[ 43.,  42.,  73., 184.,  89.,  92., 180.,  31.,  35.,  38.,  86.]])\n",
    "d = torch.Tensor([[164., 164., 157., 348., 124., 120., 202.,  76.,  59.,  88., 193.]])\n",
    "\n",
    "torch.cat((c.view(-1, 1), d.view(-1, 1)), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4b12921c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2, 4] at entry 0 and [1, 4] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19220/2649070746.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_data_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19220/2497766238.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, batch_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loc_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2, 4] at entry 0 and [1, 4] at entry 1"
     ]
    }
   ],
   "source": [
    "batch = 8\n",
    "\n",
    "train_data_loader = DataLoader(train_data, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa0ad9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7544/751141809.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for idx in range(train_data_loader.iter() + 1):\n",
    "    x, y = train_data_loader.next(idx)\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04da6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face_detect_model(nn.Module):\n",
    "    def __init__(self, backbone='resnet', conf=None) -> None:\n",
    "        super().__init__()\n",
    "        if conf:\n",
    "            self._class_num = conf.class_num\n",
    "            self._class_label = conf.class_label\n",
    "        else:\n",
    "            self._class_label = ['face']\n",
    "            self._class_num = len(self._class_label)\n",
    "\n",
    "        self._anchors = [4, 8, 16, 32, 64, 128]\n",
    "        def get_anchor(eps):\n",
    "            from math import pow\n",
    "            return [[int(pow(2, i)) * eps for _ in range(2)] for i in range(2, 8)]\n",
    "\n",
    "        eps = 2 ** (4/3)\n",
    "        anchor_list = get_anchor(eps)\n",
    "        self.num_anchors = len(anchor_list)\n",
    "\n",
    "        if backbone == 'resnet':\n",
    "            self._backbone = FPN(num_blocks=[3,4,6,3])\n",
    "        else:\n",
    "            pass\n",
    "        self.reg_head = self._make_head(self.num_anchors * 4, iou=True)\n",
    "        self.cls_head = self._make_head(self.num_anchors * self._class_num)\n",
    "\n",
    "        self.loc_head = self._loc_head(self.num_anchors * 4) # 바운딩 박스 좌표 예측\n",
    "        self.iou_head = self._iou_head()\n",
    "    \n",
    "    def foward(self, x):\n",
    "        fms = self._backbone(x)\n",
    "        loc_preds = []\n",
    "        cls_preds = []\n",
    "        iou_preds = []\n",
    "        for fm in fms: \n",
    "            reg_pred = self.reg_head(fm)\n",
    "            cls_pred = self.cls_head(fm)\n",
    "            loc_pred = self.loc_head(reg_pred)\n",
    "            iou_pred = self.iou_head(reg_pred)\n",
    "\n",
    "            loc_pred = loc_pred.permute(0,2,3,1).contiguous().view(x.size(0),-1,4)  # [N, 9*4,H,W] -> [N,H,W, 9*4] -> [N,H*W*9, 4]\n",
    "            cls_pred = cls_pred.permute(0,2,3,1).contiguous().view(x.size(0),-1,self.num_classes) # [N,9,H,W] -> [N,H,W,9*20] -> [N,H*W*9,20]\n",
    "            iou_pred = self._iou_aware(iou_pred)\n",
    "\n",
    "            loc_preds.append(loc_pred)\n",
    "            cls_preds.append(cls_pred)\n",
    "            iou_preds.append(iou_pred)\n",
    "        return torch.cat(loc_preds,1), torch.cat(cls_preds,1), torch.cat(iou_preds,1)\n",
    "\n",
    "    def _make_head(self, out_channels, iou=False): # 예측을 수행하는 Layer 생성\n",
    "        layers = []\n",
    "        for _ in range(4):\n",
    "            layers.append(nn.Conv2d(256,256,3, stride=1, padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "        if iou:\n",
    "            return nn.Sequential(*layers)\n",
    "        layers.append(nn.Conv2d(256, out_channels, 3, stride=1, padding=1)) # (batch,9*4,H,W) or (batch,9,H,W) \n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _loc_head(self, out_channels):\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(256, out_channels, 3, stride=1, padding=1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _iou_head(self):\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(256, 3, 3, stride=1, padding=1)) # (batch, 9, H, W)\n",
    "        layers.append(nn.Sigmoid())# (batch, 9, H, W)\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def freeze_bn(self): # pre-trained model을 사용하므로, BN freeze\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.BatchNorm2d):\n",
    "                layer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(nn.Module):\n",
    "    def __init__(self, num_blocks):\n",
    "        super(FPN, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, 7, stride=2, padding=3, bias=False) # 640x640\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1) # 320x320\n",
    "\n",
    "        self.layer1 = self._make_layer(64, num_blocks[0], stride=1)  # c2, 320x320\n",
    "        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)  # c3 160x160\n",
    "        self.layer3 = self._make_layer(256, num_blocks[2], stride=2, DCN=True) # c4 80x80\n",
    "        self.layer4 = self._make_layer(512, num_blocks[3], stride=2, DCN=True) # c5\n",
    "        self.conv6 = nn.Conv2d(2048, 256, 3, stride=2, padding=1)    # p6\n",
    "        self.conv7 = nn.Sequential(                                  # p7\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        # Lateral layers\n",
    "        self.lateral_1 = nn.Conv2d(2048, 256, 1, stride=1, padding=0)\n",
    "        self.lateral_2 = nn.Conv2d(1024, 256, 1, stride=1, padding=0)\n",
    "        self.lateral_3 = nn.Conv2d(512, 256, 1, stride=1, padding=0)\n",
    "        self.lateral_4 = nn.Conv2d(256, 256, 1, stride=1, padding=0)\n",
    "\n",
    "        # Top-down layers\n",
    "        self.top_down_1 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
    "        self.top_down_2 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
    "        self.top_down_3 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
    "\n",
    "        self.upsample_1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.upsample_2 = nn.Upsample(size=(75,75), mode='bilinear', align_corners=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extractor(ResNet)\n",
    "        c1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        c1 = self.maxpool(c1)\n",
    "        c2 = self.layer1(c1)\n",
    "        c3 = self.layer2(c2)\n",
    "        c4 = self.layer3(c3)\n",
    "        c5 = self.layer4(c4)\n",
    "\n",
    "        # FPN\n",
    "        p6 = self.conv6(c5)\n",
    "        p7 = self.conv7(p6)\n",
    "        p5 = self.lateral_1(c5)\n",
    "        p4 = self.top_down_1(self.upsample_1(p5) + self.lateral_2(c4))\n",
    "        p3 = self.top_down_2(self.upsample_2(p4) + self.lateral_3(c3))\n",
    "        p2 = self.top_down_3(self.upsample_2(p3) + self.lateral_4(c2))\n",
    "\n",
    "        return p2, p3, p4, p5, p6, p7\n",
    "\n",
    "    def _make_layer(self, inner_channels, num_block, stride, DCN=False):\n",
    "        strides = [stride] + [1] * (num_block-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BottleNeck(self.in_channels, inner_channels, stride=stride, DCN=DCN))\n",
    "            self.in_channels = inner_channels*BottleNeck.expension\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    expension = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1, DCN=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        if DCN:\n",
    "            self.residual_function = nn.Sequential(\n",
    "                DeformableConv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                DeformableConv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                DeformableConv2d(out_channels, out_channels * BottleNeck.expension, kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BottleNeck.expension),\n",
    "            )\n",
    "        else:\n",
    "            self.residual_function = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels, out_channels * BottleNeck.expension, kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BottleNeck.expension),\n",
    "            )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expension:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BottleNeck.expension, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BottleNeck.expension)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.ops\n",
    "\n",
    "class DeformableConv2d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 bias=False):\n",
    "\n",
    "        super(DeformableConv2d, self).__init__()\n",
    "        \n",
    "        assert type(kernel_size) == tuple or type(kernel_size) == int\n",
    "\n",
    "        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n",
    "        self.stride = stride if type(stride) == tuple else (stride, stride)\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.offset_conv = nn.Conv2d(in_channels, \n",
    "                                     2 * kernel_size[0] * kernel_size[1],\n",
    "                                     kernel_size=kernel_size, \n",
    "                                     stride=stride,\n",
    "                                     padding=self.padding, \n",
    "                                     bias=True)\n",
    "\n",
    "        nn.init.constant_(self.offset_conv.weight, 0.)\n",
    "        nn.init.constant_(self.offset_conv.bias, 0.)\n",
    "        \n",
    "        self.modulator_conv = nn.Conv2d(in_channels, \n",
    "                                     1 * kernel_size[0] * kernel_size[1],\n",
    "                                     kernel_size=kernel_size, \n",
    "                                     stride=stride,\n",
    "                                     padding=self.padding, \n",
    "                                     bias=True)\n",
    "\n",
    "        nn.init.constant_(self.modulator_conv.weight, 0.)\n",
    "        nn.init.constant_(self.modulator_conv.bias, 0.)\n",
    "        \n",
    "        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n",
    "                                      out_channels=out_channels,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      stride=stride,\n",
    "                                      padding=self.padding,\n",
    "                                      bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #h, w = x.shape[2:]\n",
    "        #max_offset = max(h, w)/4.\n",
    "\n",
    "        offset = self.offset_conv(x)#.clamp(-max_offset, max_offset)\n",
    "        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n",
    "        \n",
    "        x = torchvision.ops.deform_conv2d(input=x, \n",
    "                                          offset=offset, \n",
    "                                          weight=self.regular_conv.weight, \n",
    "                                          bias=self.regular_conv.bias, \n",
    "                                          padding=self.padding,\n",
    "                                          mask=modulator,\n",
    "                                          stride=self.stride,\n",
    "                                          )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f95fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "conf = EasyDict({})\n",
    "\n",
    "conf.class_label = ['humen_face']\n",
    "conf.class_num = len(conf.class_label)\n",
    "conf.iou_ths = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b73bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\cuda\\__init__.py:143: UserWarning: \n",
      "NVIDIA GeForce RTX 3070 Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 3070 Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "model = Face_detect_model(conf=conf).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face_detect_model(\n",
      "  (_backbone): FPN(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (3): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(1024, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(1024, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (3): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(1024, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (4): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(1024, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (5): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(1024, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(1024, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(512, 9, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(2048, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(2048, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(512, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): BottleNeck(\n",
      "        (residual_function): Sequential(\n",
      "          (0): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(2048, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(2048, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(512, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "          (6): DeformableConv2d(\n",
      "            (offset_conv): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (modulator_conv): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "            (regular_conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential()\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (conv6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (conv7): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (lateral_1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (lateral_2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (lateral_3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (lateral_4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (top_down_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_down_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_down_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (upsample_1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (upsample_2): Upsample(size=(75, 75), mode=bilinear)\n",
      "  )\n",
      "  (reg_head): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (cls_head): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(256, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (loc_head): Sequential(\n",
      "    (0): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (iou_head): Sequential(\n",
      "    (0): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIoULoss(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def get_metrics(self, iou_preds, p, alpha=0.5):\n",
    "        '''\n",
    "        (y_true&y_pred_iou, cls_preds)\n",
    "        '''\n",
    "        size = len(iou_preds) if len(iou_preds) == len(p) else 0\n",
    "\n",
    "        scores = []\n",
    "        for i in range(size):\n",
    "            score = (iou_preds[i] ** (1 - alpha)) * p[i] ** alpha\n",
    "            scores.append(score)\n",
    "        \n",
    "        return sum(scores) / len(scores)\n",
    "\n",
    "    def get_p(self, box1, box2):\n",
    "        w = h = img_size\n",
    "        p = 0\n",
    "        for i in range(self.batch_size):\n",
    "            points = self.get_cords((box1[i], box2[i]), w, h)\n",
    "            p += np.linalg.norm(points[0] - points[1])\n",
    "\n",
    "        return p\n",
    "\n",
    "    def get_IoU(self, box1, box2):\n",
    "        # box = (x1, y1, x2, y2)\n",
    "        # box = (x1, x2, y1, y2)\n",
    "        iou = 0\n",
    "        for i in range(self.batch_size):\n",
    "            box1_area = (box1[i, 1] - box1[i, 0] + 1) * (box1[i, 3] - box1[i, 2] + 1)\n",
    "            box2_area = (box2[i, 1] - box2[i, 0] + 1) * (box2[i, 3] - box2[i, 2] + 1)\n",
    "\n",
    "            # obtain x1, y1, x2, y2 of the intersection\n",
    "            x1 = max(box1[i, 0], box2[i, 0])\n",
    "            x2 = max(box1[i, 1], box2[i, 1])\n",
    "            y1 = min(box1[i, 2], box2[i, 2])\n",
    "            y2 = min(box1[i, 3], box2[i, 3])\n",
    "\n",
    "            # compute the width and height of the intersection\n",
    "            w = max(0, x2 - x1 + 1)\n",
    "            h = max(0, y2 - y1 + 1)\n",
    "\n",
    "            inter = w * h\n",
    "            iou += inter / (box1_area + box2_area - inter)\n",
    "        return iou\n",
    "\n",
    "    def get_cords(self, boxs, w, h):\n",
    "        '''\n",
    "        input xmin, xmax, ymin, ymax (float)\n",
    "        return (x, y) center cordinate\n",
    "        '''\n",
    "        cords = []\n",
    "        for box in boxs:\n",
    "            box_cord = np.array((int(((box[0] + box[1]) * w) / 2), int(((box[2] + box[3]) * h) / 2)))\n",
    "            cords.append(box_cord)\n",
    "        \n",
    "        return cords\n",
    "    \n",
    "    def foward(self, loc_preds, loc_targets):\n",
    "        ''' \n",
    "        Distance-IoU Loss\n",
    "        '''\n",
    "        self.batch_size = loc_preds.size()\n",
    "\n",
    "        loss = 1 - (self.get_IoU(loc_targets, loc_preds) / self.batch_size)\n",
    "        loss += self.get_p(loc_targets, loc_preds) / self.batch_size\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9bd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_up_iter = 500\n",
    "lr_down_epoch = 30\n",
    "lr_down_epoch_end = 630\n",
    "\n",
    "conf.lr = 3.75e-3\n",
    "conf.mm = 0.9\n",
    "conf.wd = 5e-4\n",
    "\n",
    "conf.lr_warmup = 10. / lr_up_iter\n",
    "\n",
    "conf.lr_down_ratio = 20. / (lr_down_epoch_end // lr_down_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Warmup(torch.optim.lr_scheduler.LambdaLR):\n",
    "    def __init__(self, optimizer, warmup_steps, last_epoch) -> None:\n",
    "\n",
    "        def lr_lambda(step):\n",
    "            if step < warmup_steps:\n",
    "                return float(step) / float(max(1.0, warmup_steps))\n",
    "            return 1.\n",
    "        \n",
    "        super().__init__(optimizer, lr_lambda, last_epoch=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc51fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = DIoULoss()\n",
    "\n",
    "\n",
    "opt = torch.optim.SGD(lr = conf.lr, momentum=conf.mm, weight_decay=conf.wd)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    opt, \n",
    "    [i for i in range(0, conf.lr_down_epoch_end, conf.lr_down_epoch)],\n",
    "    conf.lr_down_ratio\n",
    "    )\n",
    "lr_warmup = Warmup(opt, conf.lr_warmup, lr_up_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "iter = int(input('target iterlation: '))\n",
    "save_dir = \"\"\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "except:\n",
    "    print(\"Can't make save dir\")\n",
    "\n",
    "model = Face_detect_model().to(device)\n",
    "\n",
    "if iter == 0:\n",
    "    while True:\n",
    "        pass\n",
    "else:\n",
    "    for i in range(iter):\n",
    "        model, history = train(model, conf)\n",
    "        lr_warmup.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
